{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2 - Matrices de Insumo Producto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes-\n",
    "Matilda Bartoli 175/23 \\\n",
    "Florencia Allami 484/23 \\\n",
    "Luca Emilio Petrarca 1261/23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expresando $(I−A)^{-1}$ como una suma infinita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 1 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 2 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 3 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 4 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 5 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis en Componentes Principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 6 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **a) Parte 1: vector y matriz $E_n$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $E_{n}{z} = (I_{n} - \\frac{1}{n} ee^{t})z$\n",
    "\n",
    "Distribuyendo el vector $z$,  \n",
    "\n",
    "\n",
    "$E_{n}{z} = z - \\frac{1}{n} ee^{t}z$ (siendo $e^{t}z$  el producto escalar entre $e$ y $z$)\n",
    "\n",
    "Luego, \n",
    "\n",
    "\n",
    "$E_{n}{z} = z - \\frac{1}{n} e \\sum_{i=1}^{n} e_i z_i $\n",
    "\n",
    "Como $e$ es un vector de todos unos, \n",
    "\n",
    "\n",
    "$E_{n}{z} = z - \\frac{1}{n} e \\sum_{i=1}^{n}z_i $\n",
    "\n",
    "Se puede ver que $\\frac{1}{n} e \\sum_{i=1}^{n}z_i$ es un vector de $R^{n}$ donde cada componente es  el promedio de las componenentes del vector $z$. Llamando a este promedio como $z^{'}$ ,\n",
    "\n",
    "\n",
    "$E_{n}{z} = (z_{1} - z^{'}, z_{2} - z^{'}, ....., z_{n}-z^{'})  $\n",
    "\n",
    "\n",
    "Realizando el promedio de las componentes de $E_{n}{z}$, \n",
    "\n",
    "\n",
    "$\\frac{1}{n}  \\sum_{i=1}^{n}(z_i - z^{'}) $ =\n",
    "\n",
    "\n",
    "$\\frac{1}{n}  (\\sum_{i=1}^{n}z_i - \\sum_{i=1}^{n}z^{'}) $ = \n",
    "\n",
    "$\\frac{1}{n}  ((\\sum_{i=1}^{n}z_i)- nz^{'})$\n",
    "\n",
    "Dado que  $z^{'} = \\frac{1}{n} \\sum_{i=1}^{n}z_i$ , \n",
    "\n",
    "\n",
    "$nz^{'} = \\sum_{i=1}^{n}z_i$\n",
    "\n",
    "Luego, el promedio de las componentes de $E_{n}{z}$ es igual a \n",
    "\n",
    "$\\frac{1}{n}  (\\sum_{i=1}^{n}z_i- \\sum_{i=1}^{n}z_i) = 0$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### **Parte 2 : matriz y matriz $E_{n}$**\n",
    "\n",
    "Sea $E_{n}A = (I_{n} - \\frac{1}{n} ee^{t})A = A - \\frac{1}{n} ee^{t}A$\n",
    "\n",
    "Se observa que el vector que resulta de hacer $e^{t}A$ es igual a \n",
    "\n",
    "\n",
    "$e^{t}A = (\\sum_{i=1}^{n}A_{i1}, \\sum_{i=1}^{n}A_{i2}, ....., \\sum_{i=1}^{n}A_{in})$, siendo cada componente del vector la suma de cada columna de A \n",
    "\n",
    "\n",
    "Al multiplicar dicho vector por $\\frac{1}{n}e$ resulta una matriz simétrica, que llamamos $A^{'}$ de $R ^{nXn}$, donde cada componente de cada columna tiene el promedio de la respectiva columna de A (los componentes de cada columna son iguales entre si ), es decir, \n",
    "\n",
    "$(ee^{t}A)_{j} = \\frac{1}{n} \\sum_{i=1}^{n}A_{ij} $\n",
    "\n",
    "\n",
    "Luego, \n",
    "\n",
    "$E_{n}A = A - A^{'}$ \n",
    "\n",
    "\n",
    "$(E_{n}A)_{ij} = A_{ij} - A^{'}_{j}$\n",
    "\n",
    "\n",
    "Mirando el promedio de cada columna de $E_{n}A$,\n",
    "\n",
    "Promedio $(E_{n}A)_{j}$ =\n",
    "\n",
    "\n",
    "$\\frac{1}{n} \\sum_{i=1}^{n}(A_{ij} - A^{'}_{j})$ =\n",
    "\n",
    "\n",
    "$\\frac{1}{n} (\\sum_{i=1}^{n}A_{ij} - \\sum_{i=1}^{n}A^{'}_{j})$  = \n",
    "\n",
    "\n",
    "$\\frac{1}{n} (\\sum_{i=1}^{n}A_{ij} - nA^{'}_{j}$ = \n",
    "\n",
    "\n",
    "Dado que $A^{'}_{j}= \\frac{1}{n} \\sum_{i=1}^{n}A_{ij}$, \n",
    "\n",
    "\n",
    "$nA^{'}_{j} = \\sum_{i=1}^{n}A_{ij}$\n",
    "\n",
    "Luego, \n",
    "\n",
    "Promedio $(E_{n}A)_{j}$ = $\\frac{1}{n} (\\sum_{i=1}^{n}A_{ij} - \\sum_{i=1}^{n}A_{ij}) = 0 $\n",
    "\n",
    "Concluimos que cuando se le aplica a la matriz $E_{n}$ una matriz como A, devuelve una matriz donde a cada elemento de A se le resta el promedio de la columna correspondiente al elemento. Asimismo, se observa que el promedio de cada columna de la matriz resultante es igual a cero. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) \n",
    "\n",
    "#### **Autovalores y Autovectores**\n",
    "\n",
    "Para calcular los autovalores, observemos primero que $E_{n}$ es un proyector. Basta ver que $(E_{n})^2 = E_{n}$, \n",
    "\n",
    "\n",
    "$(E_{n})^2 = (I_{n} - \\frac{1}{n} ee^{t})^{2} = I_{n}^{2} - 2\\frac{1}{n} ee^{t} + \\frac{1}{n} ee^{t} = I_n - \\frac{1}{n} ee^{t} = E_{n}$\n",
    "\n",
    "Luego, $E_{n}$ es un proyector. Por lo visto en la teórica, sabemos que los únicos autovalores de los proyectores son el cero y el uno. \n",
    "\n",
    "\n",
    "Ahora calculamos los autovectores, \n",
    "\n",
    "\n",
    "Sea $v$ un autovector  $\\neq 0$ de $\\lambda = 1$ , \n",
    "\n",
    "\n",
    "$(E_{n})v= \\lambda v$\n",
    "\n",
    "\n",
    "$(I_n - \\frac{1}{n} ee^{t})v = v$\n",
    "\n",
    "\n",
    "\n",
    "$ v - \\frac{1}{n} ee^{t}v = v$\n",
    "\n",
    "\n",
    "$ - \\frac{1}{n} ee^{t}v = 0$\n",
    "\n",
    "Dado que $e^{t}v$ es el producto escalar entre $e$ y $v$ tenemos, \n",
    "\n",
    "\n",
    "$ - \\frac{1}{n} e \\sum_{i=1}^{n} e_i v_i = 0$\n",
    "\n",
    "Para que la expresión de la izquierda sea igual a cero, el producto escalar entre $e$ y $v$ debe serlo, es decir, $\\sum_{i=1}^{n} v_i = 0$ . Entonces, los autovectores asociados al autovalor $\\lambda = 1$ son los vectores ortogonales al vector $e$ y el promedio de las componentes de dichos vectores es igual a cero. Por la sugerencia de la consigna, el conjunto de estos autovectores forman un subespacio de dimension $n-1$ y es la base $\\{d_{1},d_{2},....., d_{n} \\}$. \n",
    "\n",
    "Sea $v$ un autovector $\\neq 0$ de $\\lambda = 0$, \n",
    "\n",
    "$(E_{n})v= \\lambda v$\n",
    "\n",
    "$(I_n - \\frac{1}{n} ee^{t})v = 0$\n",
    "\n",
    "\n",
    "$v - \\frac{1}{n} ee^{t}v = 0$\n",
    "\n",
    "\n",
    "$v = \\frac{1}{n} ee^{t}v$\n",
    "\n",
    "\n",
    "Luego, el autovector asociado a $\\lambda = 0$ debe ser un múltiplo del vector $e$. \n",
    "\n",
    "\n",
    "Como el subespacio de autovectores asociados a $\\lambda = 1$ tiene dimensión = $n-1$ y el de $\\lambda = 0$ dimensión $1$ , $E_{n}$ es una matriz diagonalizable ya que existe una base de autovectores de dimensión $n$ .\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Núcleo e Imagen**\n",
    "\n",
    "\n",
    "El núcleo de $E_{n}$ es la base generada por el vector $e$, es decir, $ker(E_{n}) = \\{e\\}$ con $dim = 1$.\n",
    "\n",
    "\n",
    "La imagen de $E_{n}$,  por el ejercicio a),  son todos los vectores cuyo producto escalar con $e$ es igual a cero, es decir, los que pertenecen a $\\langle e \\rangle^ {\\perp}$. Entonces, $im(E_n) = \\{d_{1},d_{2},....., d_{n} \\}$ con $dim = n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) \n",
    "\n",
    "Recordemos que  P, proyector, es ortogonal si $Ker(P) \\perp Im(P)$. O también si y solo si $E_n^T = E_n$ \n",
    "\n",
    "Ya vimos que $E_n$ es un proyector y  es  ortogonal puesto que como su imagen esta compuesta por vectores ortognales a $e$ y su núcleo por vectores multiplos de $e$, $Ker(E_n) \\perp Im(E_n)$. \n",
    "\n",
    "\n",
    "Veamos que se cumple también la segunda definición, \n",
    "\n",
    "\n",
    "$E_n^T = (I_n - \\frac{1}{n} ee^{t})^{T} = I_n^T - (\\frac{1}{n} ee^{t})^{T} = I_n - \\frac{1}{n} ee^{t} = E_n$\n",
    "\n",
    "\n",
    "\n",
    "$E_n$ proyecta sobre el subespacio ortogonal a $e$ (que ya vimos que es su imagen). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) \n",
    "\n",
    "**a) $E_n$ es una matriz ortogonal. FALSO.**\n",
    "\n",
    "Recordemos que $Q$, es una matriz ortogonal si y solo si $Q^{-1}= Q^{T}$. \n",
    "\n",
    "Veamos que $E_n$ no cumple dicha propiedad. Si la cumpliera $E_{n} E^{T} = I_{n}$, \n",
    "\n",
    "$E_{n} E^{T} = (I_n - \\frac{1}{n} ee^{t}) (I_n - \\frac{1}{n} ee^{t})^{T} = (I_n - \\frac{1}{n} ee^{t})^{2} = I_n - \\frac{1}{n} ee^{t} = E_n \\neq I_n$\n",
    "\n",
    "\n",
    "Luego, $E_n$ no es una matriz ortogonal.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**b) $E_n$ es singular . VERDADERO.**\n",
    "\n",
    "\n",
    "Antes vimos que $Ker(E_n)= \\{e\\}$, lo que signfica que la matriz  tiene un nucleo no trivial, entonces es singular. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**c) $E_n$ es definida positiva. FALSO.**\n",
    "\n",
    "\n",
    "Recordemos que $Q$ es una matriz definida positiva si para todo $x$ vector $\\neq \\vec{0}$ , $x^{T}Qx >0 $\n",
    "\n",
    "$E_n$ no es definida positiva ya que por ejemplo , tomando un vector múltiplo de $e$, que es  autovector asociado al autovalor $\\lambda = 0$ tenemos , $x^{T}E_{n}x =0$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**d) Traza $(E_n)= n-1$ VERDADERO.**\n",
    "\n",
    "Recordemos que la traza de una matriz puede calcularse como la suma de sus autovalores. Antes vimos que los autovalores de $E_n$ eran $\\lambda = 1$ (con multiplicidad $n-1$) y $\\lambda= 0$ (con multiplicidad $1$). Luego, \n",
    "\n",
    "\n",
    "$tr(E_n)= 1(n-1) + 1(0) = n-1$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 7 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 8 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz $H$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 9 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 10 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consigna 11 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
